Setting fork function. Is it node?  false
Forking systemresourcesworker: isDevBuild: false, isElectron: true
[CachedFileDataProvider] Watching file at /home/austinbm/.config/LM Studio/settings.json
[VersionMigrationProvider] Last recorded app version: v0.3.9-b3
[VersionMigrationProvider] Current app version: v0.3.9-b3
[VersionMigrationProvider] No app version update detected.
[CachedFileDataProvider] Watching file at /home/austinbm/.lmstudio/.internal/backend-preferences-v1.json
00:12:23.730 › App starting...
00:12:23.733 › [AppUpdater] Update channel set to 'stable'
[CachedFileDataProvider] Watching file at /home/austinbm/.lmstudio/.internal/http-server-config.json
[FileData] Initializing FileData
[SystemResourcesProvider] Hardware survey successfully achieved through bundled 'vulkan' liblmstudio.
00:12:23.903 › Hardware survey for general system resources through 'vulkan' took 164.03ms
[CachedFileDataProvider] Watching file at /home/austinbm/.lmstudio/.internal/hardware-config.json
[CachedFileDataProvider] Error reading file at /home/austinbm/.lmstudio/.internal/hardware-config.json _0x2a3caf [ZodError]: [
  {
    "code": "invalid_type",
    "expected": "array",
    "received": "object",
    "path": [],
    "message": "Expected array, received object"
  }
]
    at get error (/home/austinbm/squashfs-root/resources/app/.webpack/main/index.js:7:1601578)
    at _0x108678.parse (/home/austinbm/squashfs-root/resources/app/.webpack/main/index.js:7:1605597)
    at _0x1dcb50.<computed>.deserialize (/home/austinbm/squashfs-root/resources/app/.webpack/main/index.js:40:4482)
    at [deserialize] (/home/austinbm/squashfs-root/resources/app/.webpack/main/index.js:40:3956)
    at _0x1dcb50.<computed>.readData (/home/austinbm/squashfs-root/resources/app/.webpack/main/index.js:40:1137)
    at async _0x1dcb50.<computed>.createAndRefObservedFileData (/home/austinbm/squashfs-root/resources/app/.webpack/main/index.js:38:1389)
    at async _0x1dcb50.<computed>.obtainObservedFileData (/home/austinbm/squashfs-root/resources/app/.webpack/main/index.js:38:3749) {
  issues: [
    {
      code: 'invalid_type',
      expected: 'array',
      received: 'object',
      path: [],
      message: 'Expected array, received object'
    }
  ],
  addIssue: [Function (anonymous)],
  addIssues: [Function (anonymous)],
  errors: [
    {
      code: 'invalid_type',
      expected: 'array',
      received: 'object',
      path: [],
      message: 'Expected array, received object'
    }
  ]
}
[CachedFileDataProvider] Watching file at /home/austinbm/.lmstudio/credentials/lmstudio-hub.json
App is ready
[InternalPluginsProvider] Indexing installed plugins.
[CachedFileDataProvider] Watching file at /home/austinbm/.lmstudio/.internal/model-data.json
[LMSInternal][Client=LM Studio] Client created.
[ConversationsProvider][ConfigFile] Initializing FileData
00:12:24.052 › [AppUpdater] Checking for updates... (current state: idle)
00:12:24.052 › AppUpdater state changed to checking-for-updates-periodic
00:12:24.052 › [AppUpdater] Fetching version info from https://versions-prod.lmstudio.ai/update/linux/x86/0.3.9
App is ready
[LMSInternal][Client=plugin:builtin:lmstudio/default-generator] Client created.
[LMSInternal][Client=plugin:builtin:lmstudio/experimental-rag] Client created.
[LMSInternal][Client=plugin:builtin:lmstudio/rag-v1] Client created.
[FileWatchingProvider] Start syncing file watching provider... Changes may be missed during this process.
[FileWatchingProvider][Watcher-0] Sync: Subscribing to /home/austinbm/.config/LM Studio
[   Generator] Register with LM Studio
[Preprocessor] Register with LM Studio
[Preprocessor] Register with LM Studio
[LMSInternal][Client=plugin:builtin:lmstudio/default-generator][Endpoint=setGenerator] Registering generator.
[LMSInternal][Client=plugin:builtin:lmstudio/experimental-rag][Endpoint=setPreprocessor] Registering preprocessor.
[LMSInternal][Client=plugin:builtin:lmstudio/rag-v1][Endpoint=setPreprocessor] Registering preprocessor.
[FileWatchingProvider][Watcher-1] Sync: Subscribing to /home/austinbm/.lmstudio/.internal
[FileWatchingProvider][Watcher-2] Sync: Subscribing to /home/austinbm/.lmstudio/extensions/backends/vendor
[FileWatchingProvider][Watcher-3] Sync: Subscribing to /home/austinbm/.lmstudio/credentials
[FileWatchingProvider][Watcher-4] Sync: Subscribing to /home/austinbm/.lmstudio/user-files
[FileWatchingProvider][Watcher-5] Sync: Subscribing to /home/austinbm/.lmstudio/conversations
[FileWatchingProvider][Watcher-6] Sync: Subscribing to /home/austinbm/.lmstudio/config-presets
[FileWatchingProvider][Watcher-7] Sync: Subscribing to /home/austinbm/.lmstudio/hub/presets
[FileWatchingProvider] Sync completed.
Preload script prod path /home/austinbm/squashfs-root/resources/app/.webpack/main/main_window_preload.js
process.env.NODE_ENV production
00:12:24.327 › [AppUpdater] Received version info response
00:12:24.328 › [AppUpdater] Current version: 0.3.9 (build: 3), new version: 0.3.27 (build: 4)
00:12:24.328 › Update available: 0.3.27 > 0.3.9
00:12:24.328 › AppUpdater state changed to update-available
[CachedFileDataProvider] Watching file at /home/austinbm/.lmstudio/.internal/ui-state/global.json
[DelayedInitProvider] Running delayed init: update lms
[LmsProvider] Extracting lms from /home/austinbm/squashfs-root/resources/app/.webpack/lms to /home/austinbm/.lmstudio/bin/lms
[DelayedInitProvider] Running delayed init: autoStartServer
[DelayedInitProvider] Running delayed init: ModelIndexProvider
[DelayedInitProvider] Running delayed init: Unbundle dependencies
[ModelIndexProvider] Directory added: /home/austinbm/.lmstudio/models
[BundledDepsUnpackager] Unbundling engines from the app installer... (/home/austinbm/squashfs-root/resources/app/.webpack/bin/extensions/backends -> /home/austinbm/.lmstudio/extensions/backends)
[DelayedInitProvider] Running delayed init: LoginItemSync
[DelayedInitProvider] Running delayed init: Extract utils
[DelayedInitProvider] Running delayed init: startAPIServer
[APIServerProvider] Trying to start the API Server on port: 41343
[DelayedInitProvider] Running delayed init: Refresh backends master list
[DelayedInitProvider] Running delayed init after UI: plugins init load
[APIServerProvider] API Server started on port: 41343
[ModelIndexProvider][Op-1] Requested to index directory: /home/austinbm/.lmstudio/models
[ModelIndexProvider][Op-1] Starting indexing operation on directory: /home/austinbm/.lmstudio/models
[ModelIndexProvider] Directory added: /home/austinbm/squashfs-root/resources/app/.webpack/bin/bundled-models
[UtilsProvider] Skipping extraction of esbuild because it already exists.
[ModelIndexProvider][Op-2] Requested to index directory: /home/austinbm/squashfs-root/resources/app/.webpack/bin/bundled-models
[ModelIndexProvider][Op-2] Starting indexing operation on directory: /home/austinbm/squashfs-root/resources/app/.webpack/bin/bundled-models
[FileWatchingProvider] Start syncing file watching provider... Changes may be missed during this process.
[FileWatchingProvider][Watcher-8] Sync: Subscribing to /home/austinbm/.lmstudio/models
[UtilsProvider] Skipping extraction of node because it already exists.
[BundledDepsUnpackager] ✅ Finished unbundling engines from the app installer. [6.14 ms], hasAnythingMoved: false
[BundledDepsUnpackager] Unbundling frameworks from the app installer... (/home/austinbm/squashfs-root/resources/app/.webpack/bin/extensions/frameworks -> /home/austinbm/.lmstudio/extensions/frameworks)
[BundledDepsUnpackager] No bundled source directory found at '/home/austinbm/squashfs-root/resources/app/.webpack/bin/extensions/frameworks'. Nothing to unbundle.
[BackendManager] Performing backend hardware survey...
[FileWatchingProvider][Watcher-9] Sync: Subscribing to /home/austinbm/squashfs-root/resources/app/.webpack/bin/bundled-models
[BackendManager] Extensions backends directory already exists at /home/austinbm/.lmstudio/extensions/backends
[BackendManager] Surveying backend-hardware compatibility...
[CachedFileDataProvider] Watching file at /home/austinbm/.lmstudio/.internal/ui-state/window-1.json
[FileWatchingProvider] Sync completed.
[LmsProvider] Extracted lms successfully
[BackendManager] Hardware survey for runtime 'llama.cpp-linux-x86_64-avx2', version '1.23.0' took 162.83ms
[CachedFileDataProvider] Watching file at /home/austinbm/.lmstudio/conversations/1744029481540.conversation.json
[CachedFileDataProvider] Watching file at /home/austinbm/.lmstudio/.internal/user-concrete-model-default-config/.json
[BackendManager] Hardware survey for runtime 'llama.cpp-linux-x86_64-avx2', version '1.24.1' took 113.25ms
[BackendManager] Hardware survey for runtime 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', version '1.11.0' took 372.01ms
[BackendManager] Hardware survey for runtime 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', version '1.15.3' took 228.06ms
[BackendManager] Hardware survey for runtime 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', version '1.16.1' took 235.59ms
[BackendManager] Hardware survey for runtime 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', version '1.18.0' took 236.07ms
[BackendManager] Hardware survey for runtime 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', version '1.19.2' took 230.69ms
[BackendManager] Hardware survey for runtime 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', version '1.20.1' took 229.68ms
[BackendManager] Hardware survey for runtime 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', version '1.21.0' took 237.64ms
[BackendManager] Hardware survey for runtime 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', version '1.22.0' took 237.14ms
[BackendManager] Hardware survey for runtime 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', version '1.23.0' took 233.76ms
[BackendManager] Hardware survey for runtime 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', version '1.23.2' took 240.43ms
[BackendManager] Hardware survey for runtime 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', version '1.24.1' took 233.76ms
[BackendManager] Hardware survey for runtime 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', version '1.25.2' took 218.16ms
[BackendManager] Hardware survey for runtime 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', version '1.26.0' took 223.06ms
[BackendManager] Hardware survey for runtime 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', version '1.30.1' took 234.28ms
[BackendManager] Hardware survey for runtime 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', version '1.51.0' took 230.30ms
[BackendManager] Hardware survey for runtime 'llama.cpp-linux-x86_64-vulkan-avx2', version '1.23.0' took 178.35ms
[BackendManager] Hardware survey for runtime 'llama.cpp-linux-x86_64-vulkan-avx2', version '1.24.1' took 167.72ms
[BackendManager] Backend-hardware compatibility survey complete
[BackendManager] Updating backend preferences file at '/home/austinbm/.lmstudio/.internal/backend-preferences-v1.json' for current environment...
[BackendManager] Detecting the 'best backend' available for use for model format 'gguf'...
[BackendManager] First compatible backend found on non-mac is 'llama.cpp-linux-x86_64-avx2', version '1.23.0', setting as best
[BackendManager] Comparing two versions of backend 'llama.cpp-linux-x86_64-avx2', '1.24.1' to '1.23.0'
[BackendManager] Setting version '1.24.1' as best, since it has a higher version than '1.23.0'
[BackendManager] Backend 'llama.cpp-linux-x86_64-nvidia-cuda-avx2' has GPU acceleration, while 'llama.cpp-linux-x86_64-avx2' does not. Setting 'llama.cpp-linux-x86_64-nvidia-cuda-avx2' as best
[BackendManager] Comparing two versions of backend 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', '1.15.3' to '1.11.0'
[BackendManager] Setting version '1.15.3' as best, since it has a higher version than '1.11.0'
[BackendManager] Comparing two versions of backend 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', '1.16.1' to '1.15.3'
[BackendManager] Setting version '1.16.1' as best, since it has a higher version than '1.15.3'
[BackendManager] Comparing two versions of backend 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', '1.18.0' to '1.16.1'
[BackendManager] Setting version '1.18.0' as best, since it has a higher version than '1.16.1'
[BackendManager] Comparing two versions of backend 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', '1.19.2' to '1.18.0'
[BackendManager] Setting version '1.19.2' as best, since it has a higher version than '1.18.0'
[BackendManager] Comparing two versions of backend 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', '1.20.1' to '1.19.2'
[BackendManager] Setting version '1.20.1' as best, since it has a higher version than '1.19.2'
[BackendManager] Comparing two versions of backend 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', '1.21.0' to '1.20.1'
[BackendManager] Setting version '1.21.0' as best, since it has a higher version than '1.20.1'
[BackendManager] Comparing two versions of backend 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', '1.22.0' to '1.21.0'
[BackendManager] Setting version '1.22.0' as best, since it has a higher version than '1.21.0'
[BackendManager] Comparing two versions of backend 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', '1.23.0' to '1.22.0'
[BackendManager] Setting version '1.23.0' as best, since it has a higher version than '1.22.0'
[BackendManager] Comparing two versions of backend 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', '1.23.2' to '1.23.0'
[BackendManager] Setting version '1.23.2' as best, since it has a higher version than '1.23.0'
[BackendManager] Comparing two versions of backend 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', '1.24.1' to '1.23.2'
[BackendManager] Setting version '1.24.1' as best, since it has a higher version than '1.23.2'
[BackendManager] Comparing two versions of backend 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', '1.25.2' to '1.24.1'
[BackendManager] Setting version '1.25.2' as best, since it has a higher version than '1.24.1'
[BackendManager] Comparing two versions of backend 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', '1.26.0' to '1.25.2'
[BackendManager] Setting version '1.26.0' as best, since it has a higher version than '1.25.2'
[BackendManager] Comparing two versions of backend 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', '1.30.1' to '1.26.0'
[BackendManager] Setting version '1.30.1' as best, since it has a higher version than '1.26.0'
[BackendManager] Comparing two versions of backend 'llama.cpp-linux-x86_64-nvidia-cuda-avx2', '1.51.0' to '1.30.1'
[BackendManager] Setting version '1.51.0' as best, since it has a higher version than '1.30.1'
[BackendManager] Current best backend 'llama.cpp-linux-x86_64-nvidia-cuda-avx2' is ROCM or CUDA, so not considering 'llama.cpp-linux-x86_64-vulkan-avx2' which is non-ROCM/non-CUDA
[BackendManager] Current best backend 'llama.cpp-linux-x86_64-nvidia-cuda-avx2' is ROCM or CUDA, so not considering 'llama.cpp-linux-x86_64-vulkan-avx2' which is non-ROCM/non-CUDA
[BackendManager] Best 'gguf' backend for detected to be 'llama.cpp-linux-x86_64-nvidia-cuda-avx2'
[BackendManager] Detecting the 'best backend' available for use for model format 'safetensors'...
[BackendManager] Failed to get best backend for model format 'safetensors': Best backend options is null after logic attempting to get!
[BackendManager] Detecting the 'best backend' available for use for model format 'onnx'...
[BackendManager] Failed to get best backend for model format 'onnx': Best backend options is null after logic attempting to get!
[BackendManager] Backend preferences file update complete
[FileWatchingProvider] Start syncing file watching provider... Changes may be missed during this process.
[FileWatchingProvider][Watcher-2] Sync: Unsubscribing from /home/austinbm/.lmstudio/extensions/backends/vendor
[FileWatchingProvider][Watcher-10] Sync: Subscribing to /home/austinbm/.lmstudio/extensions/backends
[FileWatchingProvider] Sync completed.
[CachedFileDataProvider] Watching file at /home/austinbm/.lmstudio/conversations/1738411665621.conversation.json
[CachedFileDataProvider] Watching file at /home/austinbm/.lmstudio/conversations/1738412689154.conversation.json
[CachedFileDataProvider] Watching file at /home/austinbm/.lmstudio/conversations/1738413062092.conversation.json
[CachedFileDataProvider] Watching file at /home/austinbm/.lmstudio/conversations/1738433425650.conversation.json
[CachedFileDataProvider] Watching file at /home/austinbm/.lmstudio/conversations/1741901151764.conversation.json
[LMSInternal][Client=LM Studio][Endpoint=status] Getting HTTP server status signal...
[LMSInternal][Client=LM Studio][Endpoint=settings] Getting HTTP server settings writable signal...
[LMSInternal][Client=LM Studio][Endpoint=serverLogBufferData] Getting HTTP server log buffer data signal...
[CachedFileDataProvider] Watching file at /home/austinbm/.lmstudio/.internal/user-concrete-model-default-config/lmstudio-community/gemma-3-12b-it-GGUF/gemma-3-12b-it-Q3_K_L.gguf.json
[ModelLoadingProvider] Requested to load model lmstudio-community/gemma-3-12b-it-GGUF/gemma-3-12b-it-Q3_K_L.gguf with opts {
  identifier: { desired: 'gemma-3-12b-it', conflictBehavior: 'bump' },
  instanceLoadTimeConfig: { fields: [] },
  ttlMs: undefined
}
[ModelLoadingProvider] Started loading model lmstudio-community/gemma-3-12b-it-GGUF/gemma-3-12b-it-Q3_K_L.gguf
[ModelProxyObject(id=gemma-3-12b-it)] Forking LLMWorker with custom envVars: {"LD_LIBRARY_PATH":"/home/austinbm/.lmstudio/extensions/backends/vendor/linux-llama-cuda-vendor-v1"}
[ModelLoadingProvider] Requested to load model BenevolenceMessiah/nomic-embed-text-v1.5-Q8_0-GGUF/nomic-embed-text-v1.5-q8_0.gguf with opts { ttlMs: 3600000, isJIT: true }
[CachedFileDataProvider] Watching file at /home/austinbm/.lmstudio/.internal/user-concrete-model-default-config/BenevolenceMessiah/nomic-embed-text-v1.5-Q8_0-GGUF/nomic-embed-text-v1.5-q8_0.gguf.json
[ModelLoadingProvider] Started loading model BenevolenceMessiah/nomic-embed-text-v1.5-Q8_0-GGUF/nomic-embed-text-v1.5-q8_0.gguf
[ModelProxyObject(id=benevolencemessiah/text-embedding-nomic-embed-text-v1.5)] Forking LLMWorker with custom envVars: {"LD_LIBRARY_PATH":"/home/austinbm/.lmstudio/extensions/backends/vendor/linux-llama-cuda-vendor-v1"}
[CachedFileDataProvider] Watching file at /home/austinbm/.lmstudio/.internal/user-concrete-model-default-config/lmstudio-community/gemma-3-12b-it-GGUF/gemma-3-12b-it-Q3_K_L.gguf.json
00:17:10.730 › (node:19504) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 close listeners added to [Server]. MaxListeners is 10. Use emitter.setMaxListeners() to increase limit
(Use `lm-studio --trace-warnings ...` to show where the warning was created)
[CachedFileDataProvider] Watching file at /home/austinbm/.lmstudio/.internal/user-concrete-model-default-config/lmstudio-community/gemma-3-12b-it-GGUF/gemma-3-12b-it-Q3_K_L.gguf.json
[CachedFileDataProvider] Watching file at /home/austinbm/.lmstudio/.internal/user-concrete-model-default-config/lmstudio-community/gemma-3-12b-it-GGUF/gemma-3-12b-it-Q3_K_L.gguf.json
[CachedFileDataProvider] Watching file at /home/austinbm/.lmstudio/.internal/user-concrete-model-default-config/lmstudio-community/gemma-3-12b-it-GGUF/gemma-3-12b-it-Q3_K_L.gguf.json
